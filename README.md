Проект представляет из себя сверточную сеть классифицирующую эмоции. Принцип работы сети: Сеть открывает окно в котором пользователь видит трансляцию с камеры своего компьютера. Сеть в реальном времени считывает кадры с камеры и пропускает их через метод предсказания. Предсказание в виде смайлика соответствующего эмоции пользователя в реальном времени отображается в правом нижнем углу трансляции с камеры. Нажатие клавиши 'escape' останавливает процесс

Запустить тестирование работы обученной сети можно только на локальном компьютере так как библиотека cv2 с помошью которой реализовалась функция трансляции с камеры не работает на удаленных серверах. Чтобы запустить тестирование необходимо скачать файлы: 'detector.ipynb', 'emoji_array.npy' и 'model_old.h5', поместить их в одну папку и запустить файл 'detector.ipynb'. Чтобы запустить саму сеть нужно открыть ссылку и нажать 'ctrl+enter' https://colab.research.google.com/drive/1lbjhjEGzLq6rSYR3xYGRWkRmjB1UHaCO?usp=sharing

'emoji' хранит смайлики из которых был получен 'emoji_array.npy'

'data.zip' хранит архивы с данными. Данные поделены на папку 'train' хранящую 6 классов по 3171 изображений, 'test 6 по 831 и val 6 по 21. Изображения в папках 'train' и 'test' являются одноканальными и равносторонними

'detector.ipynb' хранит код запуска вебкамеры, предсказания на основе изображений с вебкамеры и вывода результата предсказания

'draft.ipynb' черновик

'emoji_array.npy' хранит смайлики из 'emoji' в виде массива

'model_old.h5' неправильно обученная модель просто чтобы было на чем делать инференс

'network.ipynb' хранит код обучения сети
